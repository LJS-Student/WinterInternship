{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필요한 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = names=['user_id', 'movie_id', 'ratings', 'timestamp']\n",
    "rating_df = pd.read_csv(\"../Data/MovieLens/ml-1m/ratings.dat\", sep=\"::\", names=col_names, engine='python')\n",
    "rating_df.drop('timestamp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"movie_id\",\"movie_name\", \"genre\"]\n",
    "item_df = pd.read_table(\"../Data/MovieLens/ml-1m/movies.dat\", sep=\"::\", names=col_names, encoding = \"latin-1\", engine='python')\n",
    "item_df['genre'] = item_df.apply(lambda row: row['genre'].split('|')[0], axis=1)\n",
    "item_df['movie_year'] = item_df.apply(lambda row : int(row['movie_name'].split(\"(\")[-1][:-1]),axis=1)\n",
    "item_df.drop(['movie_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"user_id\", \"gender\", \"age\", \"occupation\", \"zipcode\"]\n",
    "user_df = pd.read_table('../Data/MovieLens/ml-1m/users.dat', sep=\"::\", names=col_names, engine='python')\n",
    "user_df['gender'] = (user_df['gender'].apply(lambda x: 1 if x=='M' else 0)).astype(int)\n",
    "user_df.drop(['zipcode'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item-user cartesian product\n",
    "item_df['key'] = 0\n",
    "user_df['key'] = 0\n",
    "user_item_df = user_df.merge(item_df, how='outer')\n",
    "user_item_df.drop('key', axis=1, inplace=True)\n",
    "\n",
    "user_item_index_df = user_item_df.iloc[:, [0,4]]\n",
    "user_item_feature_df = pd.concat([user_item_df.iloc[:,[1,2,3]], user_item_df.iloc[:,5:]], axis=1)\n",
    "user_item_df = pd.concat([user_item_index_df, user_item_feature_df], axis=1)\n",
    "\n",
    "user_item_df = pd.merge(user_item_df, rating_df, how='left', on=['user_id', 'movie_id'])\n",
    "user_item_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler = StandardScaler()\n",
    "user_item_df['movie_year']=Scaler.fit_transform(user_item_df['movie_year'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide Component 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_cols = ['movie_year']\n",
    "cross_cols = ['gender', 'genre', 'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_df = user_item_df.loc[:, continous_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_df = user_item_df.loc[:, cross_cols]\n",
    "cross_df = pd.get_dummies(cross_df, columns=['age'])\n",
    "cross_df = pd.get_dummies(cross_df, columns=['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interacion\n",
    "cross_df = PolynomialFeatures(2, interaction_only=True, include_bias=False).fit_transform(cross_df)\n",
    "cross_df = pd.DataFrame(cross_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_df.reset_index(drop=True,inplace=True)\n",
    "cross_df.reset_index(drop=True, inplace=True)\n",
    "wide_df = pd.concat([continous_df,cross_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_year</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>341</th>\n",
       "      <th>342</th>\n",
       "      <th>343</th>\n",
       "      <th>344</th>\n",
       "      <th>345</th>\n",
       "      <th>346</th>\n",
       "      <th>347</th>\n",
       "      <th>348</th>\n",
       "      <th>349</th>\n",
       "      <th>350</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.578536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.578536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.578536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.675879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.439156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>-0.188051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>-0.397120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>-0.954638</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>0.926984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>-0.048672</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 352 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         movie_year    0    1    2    3    4    5    6    7    8  ...  341  \\\n",
       "0          0.578536  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1          0.578536  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "2          0.578536  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "3         -0.675879  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0   \n",
       "4          0.439156  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1000204   -0.188051  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1000205   -0.397120  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  ...  0.0   \n",
       "1000206   -0.954638  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1000207    0.926984  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1000208   -0.048672  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "\n",
       "         342  343  344  345  346  347  348  349  350  \n",
       "0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "1000204  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1000205  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1000206  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1000207  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1000208  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[1000209 rows x 352 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wide_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Components 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_cols = ['user_id', 'movie_id', 'occupation', 'genre', 'gender', 'age']\n",
    "deep_df =  user_item_df[deep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "genre = le.fit_transform(deep_df.loc[:,'genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junseok/anaconda3/envs/study/lib/python3.8/site-packages/pandas/core/indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "deep_df.loc[ : ,'genre'] = genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>occupation</th>\n",
       "      <th>genre</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>1</td>\n",
       "      <td>527</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  movie_id  occupation  genre  gender  age\n",
       "0          1         1          10      2       0    1\n",
       "47         1        48          10      2       0    1\n",
       "148        1       150          10      7       0    1\n",
       "257        1       260          10      0       0    1\n",
       "523        1       527          10      7       0    1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(user_item_df['ratings'])\n",
    "Y = np.where(Y>=3, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wide_df, test_wide_df = train_test_split(wide_df, test_size=0.3, random_state=22)\n",
    "train_deep_df, test_deep_df = train_test_split(deep_df, test_size=0.3, random_state=22)\n",
    "train_Y, test_Y = train_test_split(Y, test_size=0.3, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PandasDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, wide_df, deep_df, Y):\n",
    "        \"\"\"\n",
    "        Args :  wide_df : Features for Wide Learning\n",
    "                deep_df : Features for Deep Learning\n",
    "                Y       : target\n",
    "        \"\"\"\n",
    "        super(PandasDataset, self).__init__()\n",
    "        self.X = wide_df\n",
    "        self.emb_user = deep_df.iloc[:,0]\n",
    "        self.emb_movie = deep_df.iloc[:,1]\n",
    "        self.emb_occupation = deep_df.iloc[:,2]\n",
    "        self.emb_genre = deep_df.iloc[:,3]\n",
    "        self.emb_gender = deep_df.iloc[:,4]\n",
    "        self.emb_age = deep_df.iloc[:,5]\n",
    "        \n",
    "        self.y = Y\n",
    "        \n",
    "        self.X_value = self.X.values\n",
    "        self.emb_user_value, self.emb_movie_value, self.emb_occupation_value = self.emb_user.values, self.emb_movie.values, self.emb_occupation.values\n",
    "        self.emb_genre_value, self.emb_gender_value, self.emb_age_value = self.emb_genre.values, self.emb_gender.values, self.emb_age.values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'X' : torch.from_numpy(self.X_value)[idx],\n",
    "            'emb_user' : torch.from_numpy(self.emb_user_value)[idx],\n",
    "            'emb_movie' : torch.from_numpy(self.emb_movie_value)[idx],\n",
    "            'emb_occupation' : torch.from_numpy(self.emb_occupation_value)[idx],\n",
    "            'emb_genre' : torch.from_numpy(self.emb_genre_value)[idx],\n",
    "            'emb_gender' : torch.from_numpy(self.emb_gender_value)[idx],\n",
    "            'emb_age' : torch.from_numpy(self.emb_age_value)[idx],\n",
    "            'y' : torch.from_numpy(self.y)[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "\n",
    "train_dataset = PandasDataset(train_wide_df, train_deep_df, train_Y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "test_wide_tensor = torch.FloatTensor(test_wide_df.values)\n",
    "test_emb1_tensor = torch.LongTensor(test_deep_df.iloc[:,0].values)\n",
    "test_emb2_tensor = torch.LongTensor(test_deep_df.iloc[:,1].values)\n",
    "test_emb3_tensor = torch.LongTensor(test_deep_df.iloc[:,2].values)\n",
    "test_emb4_tensor = torch.LongTensor(test_deep_df.iloc[:,3].values)\n",
    "test_emb5_tensor = torch.LongTensor(test_deep_df.iloc[:,4].values)\n",
    "test_emb6_tensor = torch.LongTensor(test_deep_df.iloc[:,5].values)\n",
    "test_y_tensor = torch.FloatTensor(test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide&Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>occupation</th>\n",
       "      <th>genre</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>1</td>\n",
       "      <td>527</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  movie_id  occupation  genre  gender  age\n",
       "0          1         1          10      2       0    1\n",
       "47         1        48          10      2       0    1\n",
       "148        1       150          10      7       0    1\n",
       "257        1       260          10      0       0    1\n",
       "523        1       527          10      7       0    1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(deep_df['age'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wide_n_Deep(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Wide_n_Deep, self).__init__()\n",
    "         \n",
    "        # deep components embedding\n",
    "        self.embed1 = nn.Embedding(6041,32)\n",
    "        self.embed2 = nn.Embedding(4000,32)\n",
    "        self.embed3 = nn.Embedding(22,8)\n",
    "        self.embed4 = nn.Embedding(19, 8)\n",
    "        self.embed5 = nn.Embedding(2, 8)\n",
    "        self.embed6 = nn.Embedding(200, 8)\n",
    "        \n",
    "        # deep model\n",
    "        self.lin1 = nn.Linear(96, 50)\n",
    "        self.lin2 = nn.Linear(50, 32)\n",
    "        self.lin3 = nn.Linear(32, 16)\n",
    "        \n",
    "        # integrate\n",
    "        self.lin4 = nn.Linear(368, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, emb_user, emb_movie, emb_occupation, emb_genre, emb_gender, emb_age):\n",
    "        \n",
    "        # deep components embedding\n",
    "        input_emb1_out = self.embed1(emb_user)\n",
    "        input_emb2_out = self.embed2(emb_movie)\n",
    "        input_emb3_out = self.embed3(emb_occupation)\n",
    "        input_emb4_out = self.embed4(emb_genre)\n",
    "        input_emb5_out = self.embed5(emb_gender)\n",
    "        input_emb6_out = self.embed6(emb_age)\n",
    "        \n",
    "        # deep components integrate\n",
    "        concat_out = torch.cat((input_emb1_out, input_emb2_out, input_emb3_out, input_emb4_out, input_emb5_out, input_emb6_out), dim=1)\n",
    "        \n",
    "        # deep model learning\n",
    "        lin1_out = self.lin1(concat_out)\n",
    "        relu1_out = nn.ReLU()(lin1_out)\n",
    "        lin2_out = self.lin2(relu1_out)\n",
    "        relu2_out = nn.ReLU()(lin2_out)\n",
    "        lin3_out = self.lin3(relu2_out)\n",
    "        deep_out = nn.ReLU()(lin3_out)\n",
    "        \n",
    "        # integrate\n",
    "        wide_deep_input = torch.cat([x, deep_out], dim=1)\n",
    "        logits = self.lin4(wide_deep_input)\n",
    "        \n",
    "        # sigmoid\n",
    "        output = self.sigmoid(logits)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wide_n_Deep()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "lr = 0.005\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=lr)\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, train_loss : 0.6300391783105567, auc : 0.517118057771245\n",
      "epoch : 2, train_loss : 0.536460577173436, auc : 0.5186190440744675\n",
      "epoch : 3, train_loss : 0.49474412519881067, auc : 0.5227202925468466\n",
      "epoch : 4, train_loss : 0.47476847395829275, auc : 0.527538605570456\n",
      "epoch : 5, train_loss : 0.46391459475172325, auc : 0.5326610601261419\n",
      "epoch : 6, train_loss : 0.4577722238733413, auc : 0.5376816016130292\n",
      "epoch : 7, train_loss : 0.45339440390573327, auc : 0.5424925929281192\n",
      "epoch : 8, train_loss : 0.4508193682694266, auc : 0.5469997551078234\n",
      "epoch : 9, train_loss : 0.44842425157837834, auc : 0.5513400750563598\n",
      "epoch : 10, train_loss : 0.44730958321415787, auc : 0.5554157129350165\n",
      "epoch : 11, train_loss : 0.4463685315551487, auc : 0.559225036232264\n",
      "epoch : 12, train_loss : 0.4448931929490245, auc : 0.562751705523941\n",
      "epoch : 13, train_loss : 0.44462843165330007, auc : 0.5660867717828971\n",
      "epoch : 14, train_loss : 0.4437250704207319, auc : 0.5692105519850992\n",
      "epoch : 15, train_loss : 0.44310924601047597, auc : 0.5721453830427208\n",
      "epoch : 16, train_loss : 0.44289994662535104, auc : 0.5749018659149062\n",
      "epoch : 17, train_loss : 0.44215141923715034, auc : 0.5774647637731792\n",
      "epoch : 18, train_loss : 0.4415681945516708, auc : 0.5798812701031082\n",
      "epoch : 19, train_loss : 0.44053384873038487, auc : 0.5821454956274801\n",
      "epoch : 20, train_loss : 0.44003745173731595, auc : 0.5842489806357767\n",
      "epoch : 21, train_loss : 0.4400798014715208, auc : 0.5862973832579196\n",
      "epoch : 22, train_loss : 0.4399950071006802, auc : 0.58826035410458\n",
      "epoch : 23, train_loss : 0.4392827939479909, auc : 0.5900707166271226\n",
      "epoch : 24, train_loss : 0.43926235843212047, auc : 0.59183440009222\n",
      "epoch : 25, train_loss : 0.43908799434384554, auc : 0.5935505891790614\n",
      "epoch : 26, train_loss : 0.4383606428795673, auc : 0.5951399069982409\n",
      "epoch : 27, train_loss : 0.4378965308902957, auc : 0.5966729186573725\n",
      "epoch : 28, train_loss : 0.43790267798917515, auc : 0.5981613787272709\n",
      "epoch : 29, train_loss : 0.43746027604062504, auc : 0.599572163809163\n",
      "epoch : 30, train_loss : 0.4378099006118504, auc : 0.6009681157189407\n",
      "epoch : 31, train_loss : 0.43703862601983634, auc : 0.6022861109349129\n",
      "epoch : 32, train_loss : 0.436698816769512, auc : 0.6035523720393744\n",
      "epoch : 33, train_loss : 0.4360945425557752, auc : 0.6047387002818156\n",
      "epoch : 34, train_loss : 0.43663686788673944, auc : 0.6059251451089946\n",
      "epoch : 35, train_loss : 0.436436320450289, auc : 0.6070651349019114\n",
      "epoch : 36, train_loss : 0.4358050159528746, auc : 0.6081354119809959\n",
      "epoch : 37, train_loss : 0.4354266029723147, auc : 0.609168165888264\n",
      "epoch : 38, train_loss : 0.43556195708876805, auc : 0.6101697535813358\n",
      "epoch : 39, train_loss : 0.43528755252242934, auc : 0.6111185005834932\n",
      "epoch : 40, train_loss : 0.4352857491648789, auc : 0.6120463284300663\n",
      "epoch : 41, train_loss : 0.4352370153927634, auc : 0.6129471918284226\n",
      "epoch : 42, train_loss : 0.4341877821489429, auc : 0.6137859935286349\n",
      "epoch : 43, train_loss : 0.43536795559504354, auc : 0.6146393031181611\n",
      "epoch : 44, train_loss : 0.43435228547305926, auc : 0.6154131914282768\n",
      "epoch : 45, train_loss : 0.43414786162105856, auc : 0.6161569776648042\n",
      "epoch : 46, train_loss : 0.4339154214723736, auc : 0.6168818789217791\n",
      "epoch : 47, train_loss : 0.4343326482789736, auc : 0.6175942243114435\n",
      "epoch : 48, train_loss : 0.4340445705762146, auc : 0.6182780474970563\n",
      "epoch : 49, train_loss : 0.4341662420448682, auc : 0.6189295260195373\n",
      "epoch : 50, train_loss : 0.4334981640179952, auc : 0.6195411297975064\n",
      "epoch : 51, train_loss : 0.43377357700192337, auc : 0.620144899593293\n",
      "epoch : 52, train_loss : 0.43385458415281686, auc : 0.6207348119434156\n",
      "epoch : 53, train_loss : 0.4338750241073311, auc : 0.6212983725249474\n",
      "epoch : 54, train_loss : 0.4333879385434144, auc : 0.6218130690608059\n",
      "epoch : 55, train_loss : 0.4337866593759956, auc : 0.6223339302382473\n",
      "epoch : 56, train_loss : 0.4339348354660873, auc : 0.6228263671379389\n",
      "epoch : 57, train_loss : 0.4329082866509755, auc : 0.6232865136831494\n",
      "epoch : 58, train_loss : 0.4337487482855506, auc : 0.6237523415798637\n",
      "epoch : 59, train_loss : 0.432502733477464, auc : 0.6241563998093809\n",
      "epoch : 60, train_loss : 0.4325179861369708, auc : 0.624574900644011\n",
      "epoch : 61, train_loss : 0.43263456035167613, auc : 0.6249699250604119\n",
      "epoch : 62, train_loss : 0.4335947150879718, auc : 0.6253839810409412\n",
      "epoch : 63, train_loss : 0.4327466071497464, auc : 0.6257580195541499\n",
      "epoch : 64, train_loss : 0.4328910478040682, auc : 0.6261127357324392\n",
      "epoch : 65, train_loss : 0.43257718876743995, auc : 0.6264552733584582\n",
      "epoch : 66, train_loss : 0.4322951983475516, auc : 0.6267767744311511\n",
      "epoch : 67, train_loss : 0.43246607006864346, auc : 0.6270935433748683\n",
      "epoch : 68, train_loss : 0.43251587101753725, auc : 0.6273988561607968\n",
      "epoch : 69, train_loss : 0.43270370406461944, auc : 0.6277035419988837\n",
      "epoch : 70, train_loss : 0.432720958129734, auc : 0.6279996212573251\n",
      "epoch : 71, train_loss : 0.43230579064247454, auc : 0.6282761984257179\n",
      "epoch : 72, train_loss : 0.4327028142222276, auc : 0.628548089643748\n",
      "epoch : 73, train_loss : 0.4317192716378692, auc : 0.6287893632218617\n",
      "epoch : 74, train_loss : 0.43190013833925234, auc : 0.6290353019780925\n",
      "epoch : 75, train_loss : 0.4317253363047931, auc : 0.629273625084298\n",
      "epoch : 76, train_loss : 0.4318410424475974, auc : 0.6295009363799143\n",
      "epoch : 77, train_loss : 0.4316068300118683, auc : 0.6297182315099835\n",
      "epoch : 78, train_loss : 0.4316460314794635, auc : 0.6299308830878356\n",
      "epoch : 79, train_loss : 0.4312279746464804, auc : 0.6301391959492263\n",
      "epoch : 80, train_loss : 0.43151164181689, auc : 0.6303432857439393\n",
      "epoch : 81, train_loss : 0.43183199754843477, auc : 0.6305440310851268\n",
      "epoch : 82, train_loss : 0.4317024419916437, auc : 0.6307496962372058\n",
      "epoch : 83, train_loss : 0.4319036693860453, auc : 0.6309433414540457\n",
      "epoch : 84, train_loss : 0.43222296977719515, auc : 0.6311376388624937\n",
      "epoch : 85, train_loss : 0.4320625795962963, auc : 0.631325132933613\n",
      "epoch : 86, train_loss : 0.4310962870611367, auc : 0.6314919790265489\n",
      "epoch : 87, train_loss : 0.43077654386243075, auc : 0.6316476232692688\n",
      "epoch : 88, train_loss : 0.43155716053137544, auc : 0.631816013175025\n",
      "epoch : 89, train_loss : 0.4318143742304322, auc : 0.6319905724377858\n",
      "epoch : 90, train_loss : 0.43108426488883106, auc : 0.6321432831190754\n",
      "epoch : 91, train_loss : 0.43173448540640214, auc : 0.6323015383233379\n",
      "epoch : 92, train_loss : 0.4314671737927917, auc : 0.6324574172802403\n",
      "epoch : 93, train_loss : 0.4314446810712206, auc : 0.6326068403369667\n",
      "epoch : 94, train_loss : 0.4316476754685666, auc : 0.6327642508709833\n",
      "epoch : 95, train_loss : 0.4320183859226551, auc : 0.6329134078722325\n",
      "epoch : 96, train_loss : 0.4311053976944998, auc : 0.6330473510530119\n",
      "epoch : 97, train_loss : 0.4308212437528245, auc : 0.6331785377852277\n",
      "epoch : 98, train_loss : 0.43122093263247335, auc : 0.6333144774593154\n",
      "epoch : 99, train_loss : 0.4310694691982675, auc : 0.6334437953398115\n",
      "epoch : 100, train_loss : 0.4305900303607291, auc : 0.6335661725259957\n",
      "epoch : 101, train_loss : 0.43081307791649026, auc : 0.6336941833810137\n",
      "epoch : 102, train_loss : 0.4310751660918513, auc : 0.6338264177905117\n",
      "epoch : 103, train_loss : 0.43126197529177296, auc : 0.6339528497515973\n",
      "epoch : 104, train_loss : 0.4308501917419704, auc : 0.634073554304517\n",
      "epoch : 105, train_loss : 0.430532602553672, auc : 0.6341838887100564\n",
      "epoch : 106, train_loss : 0.4305721550968522, auc : 0.6342993652017128\n",
      "epoch : 107, train_loss : 0.4307684959672021, auc : 0.6344138378776393\n",
      "epoch : 108, train_loss : 0.43169948205034786, auc : 0.6345311236684905\n",
      "epoch : 109, train_loss : 0.430358055424183, auc : 0.6346351030269692\n",
      "epoch : 110, train_loss : 0.4306864269236301, auc : 0.6347412562761745\n",
      "epoch : 111, train_loss : 0.43085575103759766, auc : 0.634854732900557\n",
      "epoch : 112, train_loss : 0.43094403418243354, auc : 0.6349660973005472\n",
      "epoch : 113, train_loss : 0.4303130293991549, auc : 0.6350718636819181\n",
      "epoch : 114, train_loss : 0.4308544913082258, auc : 0.6351819394709651\n",
      "epoch : 115, train_loss : 0.43054807122717514, auc : 0.6352855700914853\n",
      "epoch : 116, train_loss : 0.4309035765786543, auc : 0.6353872500721088\n",
      "epoch : 117, train_loss : 0.43039615018993405, auc : 0.6354873831504975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 118, train_loss : 0.4311088951344186, auc : 0.6355886161823093\n",
      "epoch : 119, train_loss : 0.43045726080312796, auc : 0.635689370639464\n",
      "epoch : 120, train_loss : 0.4301536717313401, auc : 0.6357852071149857\n",
      "epoch : 121, train_loss : 0.4303376877561529, auc : 0.6358790825848127\n",
      "epoch : 122, train_loss : 0.4306768639713314, auc : 0.6359727789092635\n",
      "epoch : 123, train_loss : 0.43038668573325406, auc : 0.6360712078911425\n",
      "epoch : 124, train_loss : 0.4307239237406575, auc : 0.6361690075268187\n",
      "epoch : 125, train_loss : 0.43041371411465584, auc : 0.6362625795023461\n",
      "epoch : 126, train_loss : 0.4311663102596364, auc : 0.6363585891070163\n",
      "epoch : 127, train_loss : 0.4305085852636513, auc : 0.6364531566869355\n",
      "epoch : 128, train_loss : 0.43062293402692103, auc : 0.6365487437329067\n",
      "epoch : 129, train_loss : 0.4300853119674304, auc : 0.6366414777861192\n",
      "epoch : 130, train_loss : 0.4298809513132623, auc : 0.6367301920235913\n",
      "epoch : 131, train_loss : 0.43007450894261084, auc : 0.6368151968501549\n",
      "epoch : 132, train_loss : 0.4298936756367379, auc : 0.6369031737745263\n",
      "epoch : 133, train_loss : 0.43068457199326643, auc : 0.6369906652543588\n",
      "epoch : 134, train_loss : 0.43037682877364736, auc : 0.6370765851166426\n",
      "epoch : 135, train_loss : 0.4303596926496384, auc : 0.6371636774929345\n",
      "epoch : 136, train_loss : 0.42959137884437615, auc : 0.6372506190163804\n",
      "epoch : 137, train_loss : 0.43015489299246606, auc : 0.6373356255909018\n",
      "epoch : 138, train_loss : 0.4300483042466725, auc : 0.6374201874523722\n",
      "epoch : 139, train_loss : 0.42998458054048794, auc : 0.6375026109513798\n",
      "epoch : 140, train_loss : 0.4295445437549699, auc : 0.6375848679065694\n",
      "epoch : 141, train_loss : 0.4297810095421811, auc : 0.6376660695015914\n",
      "epoch : 142, train_loss : 0.4300743324536804, auc : 0.6377444495264496\n",
      "epoch : 143, train_loss : 0.4300287995778077, auc : 0.6378292760612906\n",
      "epoch : 144, train_loss : 0.4302579720392295, auc : 0.6379123284593491\n",
      "epoch : 145, train_loss : 0.43028277835101947, auc : 0.6379932052593731\n",
      "epoch : 146, train_loss : 0.4297236867830263, auc : 0.6380738119795513\n",
      "epoch : 147, train_loss : 0.4298290857609282, auc : 0.6381542675623324\n",
      "epoch : 148, train_loss : 0.43011650189440304, auc : 0.6382350133874523\n",
      "epoch : 149, train_loss : 0.4297386585397923, auc : 0.638312064882883\n",
      "epoch : 150, train_loss : 0.4297105845407391, auc : 0.6383898419028599\n",
      "epoch : 151, train_loss : 0.4300150989640689, auc : 0.6384708002878101\n",
      "epoch : 152, train_loss : 0.43067188719485666, auc : 0.6385468874794933\n",
      "epoch : 153, train_loss : 0.42938589838379665, auc : 0.6386252970163875\n",
      "epoch : 154, train_loss : 0.42963989237521555, auc : 0.6387031870438857\n",
      "epoch : 155, train_loss : 0.4304798520203178, auc : 0.6387797244363953\n",
      "epoch : 156, train_loss : 0.4297189697728935, auc : 0.6388591468946614\n",
      "epoch : 157, train_loss : 0.4301249556084897, auc : 0.6389352696146084\n",
      "epoch : 158, train_loss : 0.42990022939993133, auc : 0.6390111902624733\n",
      "epoch : 159, train_loss : 0.42974124563501237, auc : 0.6390850296207387\n",
      "epoch : 160, train_loss : 0.42989933659844365, auc : 0.6391580927636742\n",
      "epoch : 161, train_loss : 0.4294033078014428, auc : 0.6392356528336005\n",
      "epoch : 162, train_loss : 0.42986588486542937, auc : 0.6393110899881354\n",
      "epoch : 163, train_loss : 0.4294504776914069, auc : 0.6393874733977347\n",
      "epoch : 164, train_loss : 0.42954746755302375, auc : 0.6394636981903026\n",
      "epoch : 165, train_loss : 0.4295827091162932, auc : 0.6395316564013926\n",
      "epoch : 166, train_loss : 0.4294024828477954, auc : 0.6396061835608305\n",
      "epoch : 167, train_loss : 0.4292876278677731, auc : 0.6396830524149688\n",
      "epoch : 168, train_loss : 0.429093321375813, auc : 0.6397601422841764\n",
      "epoch : 169, train_loss : 0.42978830519297445, auc : 0.6398318890114403\n",
      "epoch : 170, train_loss : 0.43014441990683266, auc : 0.6399068885260567\n",
      "epoch : 171, train_loss : 0.42944116435997876, auc : 0.6399831038471308\n",
      "epoch : 172, train_loss : 0.42968034723126297, auc : 0.6400539430183088\n",
      "epoch : 173, train_loss : 0.428964819045777, auc : 0.6401291780194611\n",
      "epoch : 174, train_loss : 0.42956779020052427, auc : 0.6401997612164085\n",
      "epoch : 175, train_loss : 0.4298882241367448, auc : 0.6402731797232829\n",
      "epoch : 176, train_loss : 0.4292988749683326, auc : 0.6403487503730336\n",
      "epoch : 177, train_loss : 0.4293079357197944, auc : 0.6404212775432468\n",
      "epoch : 178, train_loss : 0.4294890628216114, auc : 0.6404965392109225\n",
      "epoch : 179, train_loss : 0.4287521260004517, auc : 0.6405744861486832\n",
      "epoch : 180, train_loss : 0.42920271830355866, auc : 0.6406475346575511\n",
      "epoch : 181, train_loss : 0.4291683944827276, auc : 0.6407184070399322\n",
      "epoch : 182, train_loss : 0.4293415962804294, auc : 0.6407912687611885\n",
      "epoch : 183, train_loss : 0.42906549530671845, auc : 0.6408667842892849\n",
      "epoch : 184, train_loss : 0.42949889843345535, auc : 0.640939814627519\n",
      "epoch : 185, train_loss : 0.42924991884130115, auc : 0.641009606365316\n",
      "epoch : 186, train_loss : 0.42922041348531736, auc : 0.6410801861882977\n",
      "epoch : 187, train_loss : 0.42933258012676917, auc : 0.6411539898963489\n",
      "epoch : 188, train_loss : 0.42933700080459, auc : 0.6412238533004262\n",
      "epoch : 189, train_loss : 0.42931075193357804, auc : 0.641292390979939\n",
      "epoch : 190, train_loss : 0.42931079103591596, auc : 0.6413629473884127\n",
      "epoch : 191, train_loss : 0.42940610921974726, auc : 0.641432132991264\n",
      "epoch : 192, train_loss : 0.4289721969171619, auc : 0.64150479731521\n",
      "epoch : 193, train_loss : 0.4292429191000918, auc : 0.6415749449860485\n",
      "epoch : 194, train_loss : 0.4292831336352842, auc : 0.6416502525884359\n",
      "epoch : 195, train_loss : 0.4297192286937795, auc : 0.6417200141231434\n",
      "epoch : 196, train_loss : 0.42895120783900537, auc : 0.6417916055260408\n",
      "epoch : 197, train_loss : 0.42909691540907463, auc : 0.6418597420288533\n",
      "epoch : 198, train_loss : 0.4290430292170099, auc : 0.6419281969039342\n",
      "epoch : 199, train_loss : 0.42900916426739794, auc : 0.6419986799388194\n",
      "epoch : 200, train_loss : 0.429018405523706, auc : 0.6420700063431447\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    total_val_loss = 0\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "        # forward pass\n",
    "        pred = model(data['X'].float().to(device), data['emb_user'].long().to(device),\n",
    "                     data['emb_movie'].long().to(device), data['emb_occupation'].long().to(device),\n",
    "                    data['emb_genre'].long().to(device), data['emb_gender'].long().to(device), data['emb_age'].long().to(device))\n",
    "        loss = loss_fn(pred.squeeze(), data['y'].float().to(device))\n",
    "        \n",
    "        # initialize\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # update\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    # evaluation\n",
    "    model.eval()\n",
    "\n",
    "    pred = model(test_wide_tensor.cuda(), test_emb1_tensor.cuda(), test_emb2_tensor.cuda(), test_emb3_tensor.cuda(),\n",
    "                test_emb4_tensor.cuda(),test_emb5_tensor.cuda(),test_emb6_tensor.cuda())\n",
    "    auc = roc_auc_score(test_y_tensor.cpu().detach().numpy(), pred.cpu().detach().numpy())\n",
    "    \n",
    "    writer.add_scalar(\"train_loss\", train_loss, epoch+1)\n",
    "    writer.add_scalar(\"AUC\", auc, epoch+1)\n",
    "    \n",
    "    print(\"epoch : {}, train_loss : {}, auc : {}\".format(epoch+1, train_loss, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
