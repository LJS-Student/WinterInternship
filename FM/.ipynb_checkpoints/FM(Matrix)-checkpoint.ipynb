{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = names=['user_id', 'movie_id', 'ratings', 'timestamp']\n",
    "df = pd.read_csv(\"../Data/MovieLens/ml-100k/u.data\", sep='\\t', names=col_names, engine='python')\n",
    "df.drop('timestamp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = df[\"user_id\"].max()\n",
    "n_items = df[\"movie_id\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_mat = np.zeros((n_users, n_items))\n",
    "for row in df.itertuples():\n",
    "    rating_mat[row[1]-1, row[2]-1] = row[3]\n",
    "rating_mat = np.array(np.vectorize(lambda x: 0 if x==0 else 1)(rating_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rated = np.zeros((len(df), n_items))\n",
    "for i in range(len(df)):\n",
    "    movie_rated[i] = rating_mat[df[\"user_id\"][i]-1]\n",
    "movie_rated = movie_rated / movie_rated.sum(axis = 1)[:, np.newaxis]\n",
    "movie_rated_df = pd.DataFrame(movie_rated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_onehot = pd.get_dummies(df.loc[:,['user_id','movie_id']], columns=['user_id', 'movie_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =pd.concat([user_item_onehot, movie_rated_df],axis=1)\n",
    "y = df.loc[:,'ratings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=22)\n",
    "y_train, y_test = train_test_split(y, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PandasDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Args : X = x\n",
    "                y= y\n",
    "        \"\"\"\n",
    "        super(PandasDataset, self).__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        self.X_value, self.y_value = self.X.values, self.y.values \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return{\n",
    "                'X' : torch.from_numpy(self.X_value)[idx],\n",
    "                'y' : torch.from_numpy(self.y_value)[idx]\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "train_dataset = PandasDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "test_X = torch.FloatTensor(X_test.values)\n",
    "test_y = torch.FloatTensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FM, self).__init__()\n",
    "        \n",
    "        self.w_0 = nn.Parameter(nn.init.normal_(torch.zeros((1, ))), requires_grad=True) # scalar\n",
    "        self.w_i = nn.Parameter(nn.init.normal_(torch.zeros((1, n_features)), std=1.0/n_features), requires_grad = True) # 1 x 13698\n",
    "        self.V = nn.Parameter(nn.init.normal_(torch.zeros((n_features, k)), std=1.0/k), requires_grad = True) # 13698 x 40\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        bias = self.w_0 + torch.mm(X, self.w_i.T) # batch x 1\n",
    "        \n",
    "        term1 = torch.sum(torch.matmul(X, self.V), dim=1)**2 # 1 x batch\n",
    "        term2 = torch.sum(torch.matmul(X, self.V)**2, dim=1) # 1 x batch\n",
    "        interaction = 0.5*(term1-term2) # 1 x batch\n",
    "        \n",
    "        output = bias + interaction.view(-1,1)\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FM()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FM()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 10, train_loss : 2.7861006259918213, test_loss : 2.757370948791504\n",
      "epoch : 20, train_loss : 2.1510207831859587, test_loss : 2.126890182495117\n",
      "epoch : 30, train_loss : 1.638580073416233, test_loss : 1.622286081314087\n",
      "epoch : 40, train_loss : 1.316809518635273, test_loss : 1.3103936910629272\n",
      "epoch : 50, train_loss : 1.179527571797371, test_loss : 1.1795697212219238\n",
      "epoch : 60, train_loss : 1.1375068709254266, test_loss : 1.1396342515945435\n",
      "epoch : 70, train_loss : 1.1259477257728576, test_loss : 1.1285741329193115\n",
      "epoch : 80, train_loss : 1.1223115161061288, test_loss : 1.1250793933868408\n",
      "epoch : 90, train_loss : 1.1206651270389556, test_loss : 1.1234776973724365\n",
      "epoch : 100, train_loss : 1.119482970237732, test_loss : 1.1223644018173218\n",
      "epoch : 110, train_loss : 1.118449442088604, test_loss : 1.1213877201080322\n",
      "epoch : 120, train_loss : 1.1174312710762024, test_loss : 1.1204578876495361\n",
      "epoch : 130, train_loss : 1.1164221450686456, test_loss : 1.1195497512817383\n",
      "epoch : 140, train_loss : 1.1154024928808213, test_loss : 1.118654727935791\n",
      "epoch : 150, train_loss : 1.1144876465201379, test_loss : 1.1177706718444824\n",
      "epoch : 160, train_loss : 1.1134974226355552, test_loss : 1.1168951988220215\n",
      "epoch : 170, train_loss : 1.112552171945572, test_loss : 1.1160271167755127\n",
      "epoch : 180, train_loss : 1.111603681743145, test_loss : 1.1151665449142456\n",
      "epoch : 190, train_loss : 1.1107100427150727, test_loss : 1.114311695098877\n",
      "epoch : 200, train_loss : 1.1097444668412209, test_loss : 1.1134631633758545\n",
      "epoch : 210, train_loss : 1.1088124498724938, test_loss : 1.11262047290802\n",
      "epoch : 220, train_loss : 1.1078949183225633, test_loss : 1.1117831468582153\n",
      "epoch : 230, train_loss : 1.1070267483592033, test_loss : 1.110950231552124\n",
      "epoch : 240, train_loss : 1.1061321794986725, test_loss : 1.1101223230361938\n",
      "epoch : 250, train_loss : 1.1051432073116303, test_loss : 1.1092991828918457\n",
      "epoch : 260, train_loss : 1.104282596707344, test_loss : 1.1084808111190796\n",
      "epoch : 270, train_loss : 1.103367029130459, test_loss : 1.107666254043579\n",
      "epoch : 280, train_loss : 1.1025189459323883, test_loss : 1.1068553924560547\n",
      "epoch : 290, train_loss : 1.101606623828411, test_loss : 1.1060492992401123\n",
      "epoch : 300, train_loss : 1.1007050275802612, test_loss : 1.105246663093567\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # forward pass\n",
    "        pred = model(data['X'].float().to(device))\n",
    "        loss = torch.sqrt(loss_fn(pred.squeeze(), data['y'].float().to(device)))\n",
    "        \n",
    "        # initialize\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # update\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    # evaluation\n",
    "    model.eval()\n",
    "    \n",
    "    pred = model(test_X.to(device))\n",
    "    test_loss = torch.sqrt(loss_fn(pred.squeeze(), test_y.to(device)))\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(\"epoch : {}, train_loss : {}, test_loss : {}\".format(epoch+1, train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.11 / 1.11"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
